{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FraudDetection.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wzqDjkUaCymk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the required libraries"
      ]
    },
    {
      "metadata": {
        "id": "92Aa6zbDCymr",
        "colab_type": "code",
        "outputId": "b6b4f889-023a-41b2-aeda-6aa989cfe1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "#dense fully connected layer# dropout is for zero noise layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pylab import rcParams\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8mcJTVCWCym8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "RANDOM_SEED =7124\n",
        "LABELS = [\"Normal\", \"Fraud\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5QwP9IE9IEss",
        "colab_type": "code",
        "outputId": "d51ce951-e7f1-42aa-cac3-3878bca673db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://s3.ap-south-1.amazonaws.com/elasticbeanstalk-ap-south-1-081954957030/Fraud_data_amtstd.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5rGSJOaQCynF",
        "colab_type": "code",
        "outputId": "830cc6a3-b3eb-4809-fa89-ac0cdfaa799b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reading the data and lookng at the structure of the data. This data has 30 attributes and 1 lakh records\n",
        "data = pd.read_csv(\"Fraud_data_amtstd.csv\")\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "zXEoZ5VCCynS",
        "colab_type": "code",
        "outputId": "69a3a3db-aca4-4347-8fa0-c9d0e70babdb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PLotting the frequencies of fraud and non-fraud transactions in the data\n",
        "count_classes = pd.value_counts(data['Class'], sort = True)\n",
        "print(count_classes)\n",
        "\n",
        "#Drawing a barplot\n",
        "count_classes.plot(kind = 'bar', rot=0)\n",
        "\n",
        "#Giving titles and labels to the plot\n",
        "plt.title(\"Transaction class distribution\")\n",
        "plt.xticks(range(2), LABELS)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\");"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    99508\n",
            "1      492\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x29987460550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FBhheFdSCyna",
        "colab_type": "code",
        "outputId": "8548eca2-fcc5-4548-a8a0-13ca566dfd1f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Looking at a sample of records\n",
        "data.head(6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.836500</td>\n",
              "      <td>-0.545419</td>\n",
              "      <td>-0.462979</td>\n",
              "      <td>0.537174</td>\n",
              "      <td>-0.426143</td>\n",
              "      <td>-0.100606</td>\n",
              "      <td>-0.584764</td>\n",
              "      <td>-0.103956</td>\n",
              "      <td>2.268429</td>\n",
              "      <td>-0.365185</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085111</td>\n",
              "      <td>0.410736</td>\n",
              "      <td>0.137625</td>\n",
              "      <td>0.602906</td>\n",
              "      <td>-0.350260</td>\n",
              "      <td>0.464407</td>\n",
              "      <td>-0.070917</td>\n",
              "      <td>-0.030486</td>\n",
              "      <td>0.049882</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-4.289880</td>\n",
              "      <td>-2.576061</td>\n",
              "      <td>-0.092256</td>\n",
              "      <td>1.976405</td>\n",
              "      <td>2.810033</td>\n",
              "      <td>-2.669128</td>\n",
              "      <td>-0.981883</td>\n",
              "      <td>-0.470310</td>\n",
              "      <td>-0.025692</td>\n",
              "      <td>0.099528</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.473240</td>\n",
              "      <td>-0.307295</td>\n",
              "      <td>-2.789549</td>\n",
              "      <td>0.578976</td>\n",
              "      <td>-0.837979</td>\n",
              "      <td>0.372843</td>\n",
              "      <td>0.353451</td>\n",
              "      <td>-1.662202</td>\n",
              "      <td>-0.347171</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.131318</td>\n",
              "      <td>0.139818</td>\n",
              "      <td>0.586921</td>\n",
              "      <td>1.069291</td>\n",
              "      <td>-0.334908</td>\n",
              "      <td>-0.204938</td>\n",
              "      <td>-0.135526</td>\n",
              "      <td>0.043821</td>\n",
              "      <td>-0.121117</td>\n",
              "      <td>0.182139</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028126</td>\n",
              "      <td>-0.167062</td>\n",
              "      <td>-0.048054</td>\n",
              "      <td>-0.009912</td>\n",
              "      <td>0.417694</td>\n",
              "      <td>-0.479793</td>\n",
              "      <td>0.024360</td>\n",
              "      <td>0.023878</td>\n",
              "      <td>-0.208963</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.866956</td>\n",
              "      <td>1.373947</td>\n",
              "      <td>1.948343</td>\n",
              "      <td>2.686750</td>\n",
              "      <td>-0.366790</td>\n",
              "      <td>0.568632</td>\n",
              "      <td>-0.278349</td>\n",
              "      <td>0.739536</td>\n",
              "      <td>-1.655955</td>\n",
              "      <td>0.708396</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022719</td>\n",
              "      <td>-0.070619</td>\n",
              "      <td>-0.080307</td>\n",
              "      <td>0.000816</td>\n",
              "      <td>0.092167</td>\n",
              "      <td>0.159131</td>\n",
              "      <td>0.157940</td>\n",
              "      <td>-0.014370</td>\n",
              "      <td>-0.253595</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.842670</td>\n",
              "      <td>1.401843</td>\n",
              "      <td>0.927235</td>\n",
              "      <td>1.070402</td>\n",
              "      <td>0.843883</td>\n",
              "      <td>0.467333</td>\n",
              "      <td>0.366716</td>\n",
              "      <td>0.616739</td>\n",
              "      <td>-1.586963</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>...</td>\n",
              "      <td>0.036573</td>\n",
              "      <td>-0.182581</td>\n",
              "      <td>-0.226834</td>\n",
              "      <td>-1.029794</td>\n",
              "      <td>-0.118762</td>\n",
              "      <td>-0.228960</td>\n",
              "      <td>-0.024250</td>\n",
              "      <td>0.046547</td>\n",
              "      <td>-0.346230</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.178458</td>\n",
              "      <td>0.166055</td>\n",
              "      <td>-0.101567</td>\n",
              "      <td>0.369453</td>\n",
              "      <td>0.017198</td>\n",
              "      <td>-0.722891</td>\n",
              "      <td>0.396639</td>\n",
              "      <td>-0.187978</td>\n",
              "      <td>-0.483147</td>\n",
              "      <td>0.083094</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.323048</td>\n",
              "      <td>-1.083814</td>\n",
              "      <td>0.049838</td>\n",
              "      <td>-0.002872</td>\n",
              "      <td>0.295810</td>\n",
              "      <td>0.135883</td>\n",
              "      <td>-0.074191</td>\n",
              "      <td>0.004364</td>\n",
              "      <td>-0.150527</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0  1.836500 -0.545419 -0.462979  0.537174 -0.426143 -0.100606 -0.584764   \n",
              "1 -4.289880 -2.576061 -0.092256  1.976405  2.810033 -2.669128 -0.981883   \n",
              "2  1.131318  0.139818  0.586921  1.069291 -0.334908 -0.204938 -0.135526   \n",
              "3 -0.866956  1.373947  1.948343  2.686750 -0.366790  0.568632 -0.278349   \n",
              "4 -0.842670  1.401843  0.927235  1.070402  0.843883  0.467333  0.366716   \n",
              "5  1.178458  0.166055 -0.101567  0.369453  0.017198 -0.722891  0.396639   \n",
              "\n",
              "         V8        V9       V10  ...         V21       V22       V23  \\\n",
              "0 -0.103956  2.268429 -0.365185  ...    0.085111  0.410736  0.137625   \n",
              "1 -0.470310 -0.025692  0.099528  ...   -0.473240 -0.307295 -2.789549   \n",
              "2  0.043821 -0.121117  0.182139  ...   -0.028126 -0.167062 -0.048054   \n",
              "3  0.739536 -1.655955  0.708396  ...    0.022719 -0.070619 -0.080307   \n",
              "4  0.616739 -1.586963  0.000041  ...    0.036573 -0.182581 -0.226834   \n",
              "5 -0.187978 -0.483147  0.083094  ...   -0.323048 -1.083814  0.049838   \n",
              "\n",
              "        V24       V25       V26       V27       V28    Amount  Class  \n",
              "0  0.602906 -0.350260  0.464407 -0.070917 -0.030486  0.049882      0  \n",
              "1  0.578976 -0.837979  0.372843  0.353451 -1.662202 -0.347171      0  \n",
              "2 -0.009912  0.417694 -0.479793  0.024360  0.023878 -0.208963      0  \n",
              "3  0.000816  0.092167  0.159131  0.157940 -0.014370 -0.253595      0  \n",
              "4 -1.029794 -0.118762 -0.228960 -0.024250  0.046547 -0.346230      0  \n",
              "5 -0.002872  0.295810  0.135883 -0.074191  0.004364 -0.150527      0  \n",
              "\n",
              "[6 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "JOMFkUBuCynj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4q67KtOCyno",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Converting data to array\n",
        "data = np.array(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPT7XPNWCynv",
        "colab_type": "code",
        "outputId": "c8cd32fe-2c80-4e3a-e1a0-0d6e1b8d5a58",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Splitting the data into train and test and observing their dimensions\n",
        "train, test = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80000, 30)\n",
            "(20000, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RdtOzrRICyoD",
        "colab_type": "code",
        "outputId": "3b3879a7-8c5d-406e-fd70-5586dc4f8e7b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Obtaining the fraud and non-fraud records in train\n",
        "print(np.unique(train[:,29], return_counts=True))\n",
        "print(np.unique(test[:,29], return_counts=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0., 1.]), array([79591,   409], dtype=int64))\n",
            "(array([0., 1.]), array([19917,    83], dtype=int64))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vPvF8X3zCyoO",
        "colab_type": "code",
        "outputId": "64d1501a-5cf9-4b8d-f771-f7cb884c7fe8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now consider only the non-fraud records for training\n",
        "train_NF = train[train[:,-1] == 0]\n",
        "X_train_NF = train_NF[:,:-1]\n",
        "\n",
        "print(X_train_NF.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79591, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rvceqFdJCyoX",
        "colab_type": "code",
        "outputId": "a9ffa79a-d230-4fc7-a5fc-eae2b09822ec",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Separating out the fraud records from the train \n",
        "train_F = train[train[:,-1] == 1]\n",
        "print(train_F.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(409, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W1Y7YBc-Cyoj",
        "colab_type": "code",
        "outputId": "6bd3eb59-d313-4ce6-ca7d-b800bad77342",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Adding/concatinating the fraud records from train data to the test\n",
        "test = np.concatenate((test, train_F),axis=0)\n",
        "print(test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20409, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PB0yjYYxCyop",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test, eval = train_test_split(test, test_size=0.2, random_state=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T3DUz9dNCyou",
        "colab_type": "code",
        "outputId": "f62e6783-dbb3-4322-d44e-bed113882c3b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(test.shape)\n",
        "print(eval.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16327, 30)\n",
            "(4082, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lxUgoKfICyo0",
        "colab_type": "code",
        "outputId": "9a1ee0e6-f491-409e-9e70-cc3e41f08311",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_NF=test[test[:,29]==0]\n",
        "print(test_NF.shape)\n",
        "\n",
        "test_F=test[test[:,29]==1]\n",
        "print(test_F.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15942, 30)\n",
            "(385, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_LKj1_OpCypJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Separating the independent and the class variable\n",
        "y_test = test[:,-1]\n",
        "X_test = test[:,:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vM_kYi6BCypV",
        "colab_type": "code",
        "outputId": "1da00981-2715-46aa-ec9a-ffd3e88ece67",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(y_test.shape)\n",
        "# Expanding the dimensions of y for later concatenation\n",
        "y_test = np.expand_dims(y_test, axis=1)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16327,)\n",
            "(16327, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7cr1PkUhCypr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Model Building"
      ]
    },
    {
      "metadata": {
        "id": "pR6uZ1pwCypt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_dim = X_train_NF.shape[1]\n",
        "encoding_dim = 15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glJ2X3DXCyp3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder = Sequential()\n",
        "#20 is masked\n",
        "autoencoder.add(Dropout(0.2, input_shape=(input_dim,)))\n",
        "autoencoder.add(Dense(encoding_dim, activation='relu'))\n",
        "autoencoder.add(Dense(input_dim, activation='linear'))\n",
        "# input linear so output linear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZHTXjB5CyqA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jzb60u1zCyqH",
        "colab_type": "code",
        "outputId": "ab0e2fd0-978e-4048-a4e4-f5f3a7d53cb6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nb_epoch = 100\n",
        "batch_size = 32\n",
        "\n",
        "hist = autoencoder.fit(X_train_NF, X_train_NF,\n",
        "                       epochs = nb_epoch,\n",
        "                       batch_size = batch_size,\n",
        "                       shuffle = True,\n",
        "                       validation_data=(X_test, X_test),\n",
        "                       verbose=1).history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 79591 samples, validate on 16327 samples\n",
            "Epoch 1/100\n",
            "79591/79591 [==============================] - 6s 74us/step - loss: 0.6020 - mean_squared_error: 0.6020 - val_loss: 0.7508 - val_mean_squared_error: 0.7508\n",
            "Epoch 2/100\n",
            "79591/79591 [==============================] - 4s 44us/step - loss: 0.3742 - mean_squared_error: 0.3742 - val_loss: 0.7051 - val_mean_squared_error: 0.7051\n",
            "Epoch 3/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.6690 - val_mean_squared_error: 0.6690\n",
            "Epoch 4/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3492 - mean_squared_error: 0.3492 - val_loss: 0.6901 - val_mean_squared_error: 0.6901\n",
            "Epoch 5/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3466 - mean_squared_error: 0.3466 - val_loss: 0.6769 - val_mean_squared_error: 0.6769\n",
            "Epoch 6/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3457 - mean_squared_error: 0.3457 - val_loss: 0.6729 - val_mean_squared_error: 0.6729\n",
            "Epoch 7/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3396 - mean_squared_error: 0.3396 - val_loss: 0.6805 - val_mean_squared_error: 0.6805\n",
            "Epoch 8/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.6903 - val_mean_squared_error: 0.6903\n",
            "Epoch 9/100\n",
            "79591/79591 [==============================] - 4s 47us/step - loss: 0.3416 - mean_squared_error: 0.3416 - val_loss: 0.6878 - val_mean_squared_error: 0.6878\n",
            "Epoch 10/100\n",
            "79591/79591 [==============================] - 4s 47us/step - loss: 0.3403 - mean_squared_error: 0.3403 - val_loss: 0.6748 - val_mean_squared_error: 0.6748\n",
            "Epoch 11/100\n",
            "79591/79591 [==============================] - 4s 46us/step - loss: 0.3378 - mean_squared_error: 0.3378 - val_loss: 0.6833 - val_mean_squared_error: 0.6833\n",
            "Epoch 12/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.6751 - val_mean_squared_error: 0.6751\n",
            "Epoch 13/100\n",
            "79591/79591 [==============================] - 4s 46us/step - loss: 0.3343 - mean_squared_error: 0.3343 - val_loss: 0.6785 - val_mean_squared_error: 0.6785\n",
            "Epoch 14/100\n",
            "79591/79591 [==============================] - 4s 48us/step - loss: 0.3340 - mean_squared_error: 0.3340 - val_loss: 0.6851 - val_mean_squared_error: 0.6851\n",
            "Epoch 15/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3353 - mean_squared_error: 0.3353 - val_loss: 0.6885 - val_mean_squared_error: 0.6885\n",
            "Epoch 16/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3321 - mean_squared_error: 0.3321 - val_loss: 0.6836 - val_mean_squared_error: 0.6836\n",
            "Epoch 17/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3304 - mean_squared_error: 0.3304 - val_loss: 0.6932 - val_mean_squared_error: 0.6932\n",
            "Epoch 18/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.6728 - val_mean_squared_error: 0.6728\n",
            "Epoch 19/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3303 - mean_squared_error: 0.3303 - val_loss: 0.6769 - val_mean_squared_error: 0.6769\n",
            "Epoch 20/100\n",
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3332 - mean_squared_error: 0.3332 - val_loss: 0.6817 - val_mean_squared_error: 0.6817\n",
            "Epoch 21/100\n",
            "79591/79591 [==============================] - 4s 47us/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.6889 - val_mean_squared_error: 0.6889\n",
            "Epoch 22/100\n",
            "79591/79591 [==============================] - 4s 46us/step - loss: 0.3307 - mean_squared_error: 0.3307 - val_loss: 0.6994 - val_mean_squared_error: 0.6994\n",
            "Epoch 23/100\n",
            "79591/79591 [==============================] - 4s 46us/step - loss: 0.3320 - mean_squared_error: 0.3320 - val_loss: 0.6806 - val_mean_squared_error: 0.6806\n",
            "Epoch 24/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3354 - mean_squared_error: 0.3354 - val_loss: 0.6796 - val_mean_squared_error: 0.6796\n",
            "Epoch 25/100\n",
            "79591/79591 [==============================] - 4s 46us/step - loss: 0.3261 - mean_squared_error: 0.3261 - val_loss: 0.6827 - val_mean_squared_error: 0.6827\n",
            "Epoch 26/100\n",
            "79591/79591 [==============================] - 4s 46us/step - loss: 0.3283 - mean_squared_error: 0.3283 - val_loss: 0.6800 - val_mean_squared_error: 0.6800\n",
            "Epoch 27/100\n",
            "79591/79591 [==============================] - 4s 46us/step - loss: 0.3329 - mean_squared_error: 0.3329 - val_loss: 0.6783 - val_mean_squared_error: 0.6783\n",
            "Epoch 28/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.6809 - val_mean_squared_error: 0.6809\n",
            "Epoch 29/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3280 - mean_squared_error: 0.3280 - val_loss: 0.6853 - val_mean_squared_error: 0.6853\n",
            "Epoch 30/100\n",
            "79591/79591 [==============================] - 4s 45us/step - loss: 0.3267 - mean_squared_error: 0.3267 - val_loss: 0.6765 - val_mean_squared_error: 0.6765\n",
            "Epoch 31/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3276 - mean_squared_error: 0.3276 - val_loss: 0.6819 - val_mean_squared_error: 0.6819\n",
            "Epoch 32/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.6716 - val_mean_squared_error: 0.6716\n",
            "Epoch 33/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3288 - mean_squared_error: 0.3288 - val_loss: 0.6865 - val_mean_squared_error: 0.6865\n",
            "Epoch 34/100\n",
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3246 - mean_squared_error: 0.3246 - val_loss: 0.6755 - val_mean_squared_error: 0.6755\n",
            "Epoch 35/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3266 - mean_squared_error: 0.3266 - val_loss: 0.6704 - val_mean_squared_error: 0.6704\n",
            "Epoch 36/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3311 - mean_squared_error: 0.3311 - val_loss: 0.6804 - val_mean_squared_error: 0.6804\n",
            "Epoch 37/100\n",
            "79591/79591 [==============================] - 5s 58us/step - loss: 0.3267 - mean_squared_error: 0.3267 - val_loss: 0.6769 - val_mean_squared_error: 0.6769\n",
            "Epoch 38/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.6835 - val_mean_squared_error: 0.6835\n",
            "Epoch 39/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3256 - mean_squared_error: 0.3256 - val_loss: 0.6691 - val_mean_squared_error: 0.6691\n",
            "Epoch 40/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.6640 - val_mean_squared_error: 0.6640\n",
            "Epoch 41/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.6763 - val_mean_squared_error: 0.6763\n",
            "Epoch 42/100\n",
            "79591/79591 [==============================] - 4s 51us/step - loss: 0.3244 - mean_squared_error: 0.3244 - val_loss: 0.6661 - val_mean_squared_error: 0.6661\n",
            "Epoch 43/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3241 - mean_squared_error: 0.3241 - val_loss: 0.6764 - val_mean_squared_error: 0.6764\n",
            "Epoch 44/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3252 - mean_squared_error: 0.3252 - val_loss: 0.6769 - val_mean_squared_error: 0.6769\n",
            "Epoch 45/100\n",
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3241 - mean_squared_error: 0.3241 - val_loss: 0.6670 - val_mean_squared_error: 0.6670\n",
            "Epoch 46/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.6859 - val_mean_squared_error: 0.6859\n",
            "Epoch 47/100\n",
            "79591/79591 [==============================] - 5s 59us/step - loss: 0.3244 - mean_squared_error: 0.3244 - val_loss: 0.6769 - val_mean_squared_error: 0.6769\n",
            "Epoch 48/100\n",
            "79591/79591 [==============================] - 4s 56us/step - loss: 0.3255 - mean_squared_error: 0.3255 - val_loss: 0.6688 - val_mean_squared_error: 0.6688\n",
            "Epoch 49/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.6698 - val_mean_squared_error: 0.6698\n",
            "Epoch 50/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3286 - mean_squared_error: 0.3286 - val_loss: 0.6546 - val_mean_squared_error: 0.6546\n",
            "Epoch 51/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3250 - mean_squared_error: 0.3250 - val_loss: 0.6604 - val_mean_squared_error: 0.6604\n",
            "Epoch 52/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3273 - mean_squared_error: 0.3273 - val_loss: 0.6855 - val_mean_squared_error: 0.6855\n",
            "Epoch 53/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.6862 - val_mean_squared_error: 0.6862\n",
            "Epoch 54/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3259 - mean_squared_error: 0.3259 - val_loss: 0.6685 - val_mean_squared_error: 0.6685\n",
            "Epoch 55/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3259 - mean_squared_error: 0.3259 - val_loss: 0.6617 - val_mean_squared_error: 0.6617\n",
            "Epoch 56/100\n",
            "79591/79591 [==============================] - 4s 51us/step - loss: 0.3250 - mean_squared_error: 0.3250 - val_loss: 0.6806 - val_mean_squared_error: 0.6806\n",
            "Epoch 57/100\n",
            "79591/79591 [==============================] - 4s 51us/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.6702 - val_mean_squared_error: 0.6702\n",
            "Epoch 58/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3219 - mean_squared_error: 0.3219 - val_loss: 0.6777 - val_mean_squared_error: 0.6777\n",
            "Epoch 59/100\n",
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3261 - mean_squared_error: 0.3261 - val_loss: 0.6650 - val_mean_squared_error: 0.6650\n",
            "Epoch 60/100\n",
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3221 - mean_squared_error: 0.3221 - val_loss: 0.6778 - val_mean_squared_error: 0.6778\n",
            "Epoch 61/100\n",
            "79591/79591 [==============================] - 5s 59us/step - loss: 0.3263 - mean_squared_error: 0.3263 - val_loss: 0.6663 - val_mean_squared_error: 0.6663\n",
            "Epoch 62/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.6806 - val_mean_squared_error: 0.6806\n",
            "Epoch 63/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.6826 - val_mean_squared_error: 0.6826\n",
            "Epoch 64/100\n",
            "79591/79591 [==============================] - 4s 48us/step - loss: 0.3246 - mean_squared_error: 0.3246 - val_loss: 0.6717 - val_mean_squared_error: 0.6717\n",
            "Epoch 65/100\n",
            "79591/79591 [==============================] - 4s 48us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.6648 - val_mean_squared_error: 0.6648\n",
            "Epoch 66/100\n",
            "79591/79591 [==============================] - 4s 48us/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.6851 - val_mean_squared_error: 0.6851\n",
            "Epoch 67/100\n",
            "79591/79591 [==============================] - 4s 48us/step - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.6583 - val_mean_squared_error: 0.6583\n",
            "Epoch 68/100\n",
            "79591/79591 [==============================] - 4s 49us/step - loss: 0.3266 - mean_squared_error: 0.3266 - val_loss: 0.6789 - val_mean_squared_error: 0.6789\n",
            "Epoch 69/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.6650 - val_mean_squared_error: 0.6650\n",
            "Epoch 70/100\n",
            "79591/79591 [==============================] - 4s 51us/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.6617 - val_mean_squared_error: 0.6617\n",
            "Epoch 71/100\n",
            "79591/79591 [==============================] - 4s 51us/step - loss: 0.3234 - mean_squared_error: 0.3234 - val_loss: 0.6612 - val_mean_squared_error: 0.6612\n",
            "Epoch 72/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3253 - mean_squared_error: 0.3253 - val_loss: 0.6758 - val_mean_squared_error: 0.6758\n",
            "Epoch 73/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3216 - mean_squared_error: 0.3216 - val_loss: 0.6640 - val_mean_squared_error: 0.6640\n",
            "Epoch 74/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.6683 - val_mean_squared_error: 0.6683\n",
            "Epoch 75/100\n",
            "79591/79591 [==============================] - 4s 56us/step - loss: 0.3249 - mean_squared_error: 0.3249 - val_loss: 0.6585 - val_mean_squared_error: 0.6585\n",
            "Epoch 76/100\n",
            "79591/79591 [==============================] - 5s 58us/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.6835 - val_mean_squared_error: 0.6835\n",
            "Epoch 77/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3247 - mean_squared_error: 0.3247 - val_loss: 0.6614 - val_mean_squared_error: 0.6614\n",
            "Epoch 78/100\n",
            "79591/79591 [==============================] - 5s 57us/step - loss: 0.3227 - mean_squared_error: 0.3227 - val_loss: 0.6722 - val_mean_squared_error: 0.6722\n",
            "Epoch 79/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3263 - mean_squared_error: 0.3263 - val_loss: 0.6683 - val_mean_squared_error: 0.6683\n",
            "Epoch 80/100\n",
            "79591/79591 [==============================] - 4s 56us/step - loss: 0.3225 - mean_squared_error: 0.3225 - val_loss: 0.6614 - val_mean_squared_error: 0.6614\n",
            "Epoch 81/100\n",
            "79591/79591 [==============================] - 5s 57us/step - loss: 0.3250 - mean_squared_error: 0.3250 - val_loss: 0.6683 - val_mean_squared_error: 0.6683\n",
            "Epoch 82/100\n",
            "79591/79591 [==============================] - 4s 56us/step - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.6537 - val_mean_squared_error: 0.6537\n",
            "Epoch 83/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.6742 - val_mean_squared_error: 0.6742\n",
            "Epoch 84/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3265 - mean_squared_error: 0.3265 - val_loss: 0.6692 - val_mean_squared_error: 0.6692\n",
            "Epoch 85/100\n",
            "79591/79591 [==============================] - 4s 56us/step - loss: 0.3242 - mean_squared_error: 0.3242 - val_loss: 0.6704 - val_mean_squared_error: 0.6704\n",
            "Epoch 86/100\n",
            "79591/79591 [==============================] - 4s 56us/step - loss: 0.3220 - mean_squared_error: 0.3220 - val_loss: 0.6707 - val_mean_squared_error: 0.6707\n",
            "Epoch 87/100\n",
            "79591/79591 [==============================] - 4s 57us/step - loss: 0.3207 - mean_squared_error: 0.3207 - val_loss: 0.6848 - val_mean_squared_error: 0.6848\n",
            "Epoch 88/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.6787 - val_mean_squared_error: 0.6787\n",
            "Epoch 89/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.6748 - val_mean_squared_error: 0.6748\n",
            "Epoch 90/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3215 - mean_squared_error: 0.3215 - val_loss: 0.6810 - val_mean_squared_error: 0.6810\n",
            "Epoch 91/100\n",
            "79591/79591 [==============================] - 4s 52us/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.6811 - val_mean_squared_error: 0.6811\n",
            "Epoch 92/100\n",
            "79591/79591 [==============================] - 4s 54us/step - loss: 0.3200 - mean_squared_error: 0.3200 - val_loss: 0.6739 - val_mean_squared_error: 0.6739\n",
            "Epoch 93/100\n",
            "79591/79591 [==============================] - 5s 57us/step - loss: 0.3216 - mean_squared_error: 0.3216 - val_loss: 0.6564 - val_mean_squared_error: 0.6564\n",
            "Epoch 94/100\n",
            "79591/79591 [==============================] - 5s 59us/step - loss: 0.3247 - mean_squared_error: 0.3247 - val_loss: 0.6685 - val_mean_squared_error: 0.6685\n",
            "Epoch 95/100\n",
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3222 - mean_squared_error: 0.3222 - val_loss: 0.6631 - val_mean_squared_error: 0.6631\n",
            "Epoch 96/100\n",
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3237 - mean_squared_error: 0.3237 - val_loss: 0.6695 - val_mean_squared_error: 0.6695\n",
            "Epoch 97/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "79591/79591 [==============================] - 4s 50us/step - loss: 0.3227 - mean_squared_error: 0.3227 - val_loss: 0.6812 - val_mean_squared_error: 0.6812\n",
            "Epoch 98/100\n",
            "79591/79591 [==============================] - 4s 53us/step - loss: 0.3205 - mean_squared_error: 0.3205 - val_loss: 0.6853 - val_mean_squared_error: 0.6853\n",
            "Epoch 99/100\n",
            "79591/79591 [==============================] - 4s 51us/step - loss: 0.3225 - mean_squared_error: 0.3225 - val_loss: 0.6693 - val_mean_squared_error: 0.6693\n",
            "Epoch 100/100\n",
            "79591/79591 [==============================] - 4s 55us/step - loss: 0.3211 - mean_squared_error: 0.3211 - val_loss: 0.6706 - val_mean_squared_error: 0.6706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jL-gwIJKCyqQ",
        "colab_type": "code",
        "outputId": "43295065-4812-49bc-db68-c33f3c43d80e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(hist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': [0.7507589702125552, 0.7051287040980526, 0.6690000083653204, 0.6900871010653393, 0.67693355635065, 0.6729460221764841, 0.680518692993976, 0.6903279469547966, 0.6877991638029463, 0.6747852705349244, 0.6833132739927397, 0.6750517156683107, 0.6785481327008053, 0.685097933627828, 0.6885201776621644, 0.6835876798663713, 0.6932391291383273, 0.6727713176669965, 0.67693515047828, 0.6816802999691391, 0.6889021598236613, 0.6994057278577043, 0.6806017168666185, 0.6795722026891977, 0.682717732208536, 0.6800061727195126, 0.6783272336616062, 0.6809327184484062, 0.6852615956878052, 0.6765109566483267, 0.6818752320789185, 0.6716293366099408, 0.6865274958007224, 0.6754862654630426, 0.6704457289852266, 0.680384565685306, 0.6769073770237822, 0.6835362250259709, 0.6691008550726704, 0.6639996219688558, 0.6762694361151167, 0.6661359296011065, 0.6763812208908351, 0.6769485516802098, 0.6669820722126586, 0.6858689682364807, 0.6768942165129795, 0.6688149567311747, 0.669787002011742, 0.6546092805431939, 0.6603979602645016, 0.6855181085670572, 0.6862335206620537, 0.6685132665083122, 0.6617263201219158, 0.6806172795583243, 0.6702119494231791, 0.6776766367386697, 0.6649745516787041, 0.6777731588017578, 0.6663453235082343, 0.6806300747602285, 0.682555785371967, 0.6716540210255217, 0.6647796777835733, 0.6851378649120899, 0.6582722437172195, 0.6788589643347451, 0.6649847781365388, 0.6616789729476391, 0.6611762181514913, 0.6758312424201612, 0.6640294458850129, 0.6683432434449889, 0.6584765245227474, 0.6834765583999584, 0.6613793212779192, 0.672170437079756, 0.6683133174339277, 0.6614459865961144, 0.6682756084031773, 0.6537472161326294, 0.6742232482251296, 0.6691995581466306, 0.6703721289886018, 0.6707348181593621, 0.6847818160116209, 0.6786935653197771, 0.6747631227365206, 0.6810230500888874, 0.681085800658381, 0.6739482820315129, 0.6564015627013219, 0.6685196922245165, 0.6630884427578398, 0.669457331083479, 0.681246054366367, 0.6852690222907389, 0.6692527508866352, 0.6706220763141952], 'val_mean_squared_error': [0.7507589702125552, 0.7051287040980526, 0.6690000083653204, 0.6900871010653393, 0.67693355635065, 0.6729460221764841, 0.680518692993976, 0.6903279469547966, 0.6877991638029463, 0.6747852705349244, 0.6833132739927397, 0.6750517156683107, 0.6785481327008053, 0.685097933627828, 0.6885201776621644, 0.6835876798663713, 0.6932391291383273, 0.6727713176669965, 0.67693515047828, 0.6816802999691391, 0.6889021598236613, 0.6994057278577043, 0.6806017168666185, 0.6795722026891977, 0.682717732208536, 0.6800061727195126, 0.6783272336616062, 0.6809327184484062, 0.6852615956878052, 0.6765109566483267, 0.6818752320789185, 0.6716293366099408, 0.6865274958007224, 0.6754862654630426, 0.6704457289852266, 0.680384565685306, 0.6769073770237822, 0.6835362250259709, 0.6691008550726704, 0.6639996219688558, 0.6762694361151167, 0.6661359296011065, 0.6763812208908351, 0.6769485516802098, 0.6669820722126586, 0.6858689682364807, 0.6768942165129795, 0.6688149567311747, 0.669787002011742, 0.6546092805431939, 0.6603979602645016, 0.6855181085670572, 0.6862335206620537, 0.6685132665083122, 0.6617263201219158, 0.6806172795583243, 0.6702119494231791, 0.6776766367386697, 0.6649745516787041, 0.6777731588017578, 0.6663453235082343, 0.6806300747602285, 0.682555785371967, 0.6716540210255217, 0.6647796777835733, 0.6851378649120899, 0.6582722437172195, 0.6788589643347451, 0.6649847781365388, 0.6616789729476391, 0.6611762181514913, 0.6758312424201612, 0.6640294458850129, 0.6683432434449889, 0.6584765245227474, 0.6834765583999584, 0.6613793212779192, 0.672170437079756, 0.6683133174339277, 0.6614459865961144, 0.6682756084031773, 0.6537472161326294, 0.6742232482251296, 0.6691995581466306, 0.6703721289886018, 0.6707348181593621, 0.6847818160116209, 0.6786935653197771, 0.6747631227365206, 0.6810230500888874, 0.681085800658381, 0.6739482820315129, 0.6564015627013219, 0.6685196922245165, 0.6630884427578398, 0.669457331083479, 0.681246054366367, 0.6852690222907389, 0.6692527508866352, 0.6706220763141952], 'loss': [0.6020286770328767, 0.3742115063983687, 0.35144169427319394, 0.3491950957547694, 0.3466472727479919, 0.3457133652162918, 0.3396330032503682, 0.33950636655807803, 0.3416192480148407, 0.3403322361027264, 0.33775541092066586, 0.33945681810696554, 0.33427583365904917, 0.3339720999805428, 0.3352579834386593, 0.3321414449087445, 0.3304319254463032, 0.33014061319236565, 0.3303285467019339, 0.33316593981787, 0.3298852735682265, 0.33069717768398166, 0.33197555407185086, 0.3353556661860322, 0.32614532438485266, 0.3282666708364858, 0.33287285672312406, 0.3291773317876169, 0.3280314676748836, 0.32672534630366645, 0.3275697357933217, 0.3270027536284624, 0.32879503888287404, 0.32461284667598356, 0.3265518664795491, 0.3310976906416606, 0.3267292073210749, 0.32425373715550426, 0.32559885434602553, 0.3231777984136564, 0.3293871217931519, 0.32441223853574974, 0.32406764188935955, 0.3252179208665555, 0.3240686898687369, 0.33003964505769445, 0.324446122280216, 0.32546888675059854, 0.3242627738540716, 0.3286087217515428, 0.32498465796453735, 0.32734499950644746, 0.3229940251038099, 0.3259416743524156, 0.32592613846327595, 0.32500239802188546, 0.3269778244592687, 0.3219398921786098, 0.3261440052333984, 0.32209961068984294, 0.32628347963149756, 0.3245490701462321, 0.32374699661788964, 0.3246021448919598, 0.3237080499057104, 0.3244962667262903, 0.32321278612745574, 0.32664319786472057, 0.32371734198757546, 0.3235263016060246, 0.3233759026512517, 0.3252826826697123, 0.3215579769466254, 0.32539639274461507, 0.3248625043982981, 0.3274544095208508, 0.324688084103861, 0.3226860273641643, 0.32634724976725404, 0.32247193296273097, 0.32498876374640395, 0.3230229227627741, 0.3245413645515386, 0.32653334908094434, 0.3242434240056942, 0.32204323818258673, 0.32070330498474386, 0.3245385074370293, 0.32095765746082694, 0.3215184571906164, 0.32400495799229356, 0.3200189085800294, 0.3216374983998393, 0.3246680772863504, 0.32218067625540814, 0.32369474403447734, 0.3226659860566748, 0.32051082848948387, 0.3225151194852245, 0.3210961707197066], 'mean_squared_error': [0.6020286770328767, 0.3742115063983687, 0.35144169427319394, 0.3491950957547694, 0.3466472727479919, 0.3457133652162918, 0.3396330032503682, 0.33950636655807803, 0.3416192480148407, 0.3403322361027264, 0.33775541092066586, 0.33945681810696554, 0.33427583365904917, 0.3339720999805428, 0.3352579834386593, 0.3321414449087445, 0.3304319254463032, 0.33014061319236565, 0.3303285467019339, 0.33316593981787, 0.3298852735682265, 0.33069717768398166, 0.33197555407185086, 0.3353556661860322, 0.32614532438485266, 0.3282666708364858, 0.33287285672312406, 0.3291773317876169, 0.3280314676748836, 0.32672534630366645, 0.3275697357933217, 0.3270027536284624, 0.32879503888287404, 0.32461284667598356, 0.3265518664795491, 0.3310976906416606, 0.3267292073210749, 0.32425373715550426, 0.32559885434602553, 0.3231777984136564, 0.3293871217931519, 0.32441223853574974, 0.32406764188935955, 0.3252179208665555, 0.3240686898687369, 0.33003964505769445, 0.324446122280216, 0.32546888675059854, 0.3242627738540716, 0.3286087217515428, 0.32498465796453735, 0.32734499950644746, 0.3229940251038099, 0.3259416743524156, 0.32592613846327595, 0.32500239802188546, 0.3269778244592687, 0.3219398921786098, 0.3261440052333984, 0.32209961068984294, 0.32628347963149756, 0.3245490701462321, 0.32374699661788964, 0.3246021448919598, 0.3237080499057104, 0.3244962667262903, 0.32321278612745574, 0.32664319786472057, 0.32371734198757546, 0.3235263016060246, 0.3233759026512517, 0.3252826826697123, 0.3215579769466254, 0.32539639274461507, 0.3248625043982981, 0.3274544095208508, 0.324688084103861, 0.3226860273641643, 0.32634724976725404, 0.32247193296273097, 0.32498876374640395, 0.3230229227627741, 0.3245413645515386, 0.32653334908094434, 0.3242434240056942, 0.32204323818258673, 0.32070330498474386, 0.3245385074370293, 0.32095765746082694, 0.3215184571906164, 0.32400495799229356, 0.3200189085800294, 0.3216374983998393, 0.3246680772863504, 0.32218067625540814, 0.32369474403447734, 0.3226659860566748, 0.32051082848948387, 0.3225151194852245, 0.3210961707197066]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ujCUpI6TCyqX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##To extract outputs from the hidden layer\n",
        "from keras import backend as K\n",
        "layer_output_encoded = K.function([autoencoder.layers[0].input, K.learning_phase()],\n",
        "                                  [autoencoder.layers[1].output])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNxVjm4hCyqc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded = layer_output_encoded([X_train_NF,0])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVc2EoSUCyqp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##To extract outputs from the output layer\n",
        "layer_output_decoded = K.function([autoencoder.layers[0].input, K.learning_phase()],\n",
        "                                  [autoencoder.layers[2].output])\n",
        "decoded = layer_output_decoded([X_train_NF, 0])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jrd8ibmjCyqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Making predictions on the train data\n",
        "predictions = autoencoder.predict(X_train_NF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BQrznuyYCyq8",
        "colab_type": "code",
        "outputId": "e567e1f5-d36c-4b0c-89c6-f0d71749d226",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Getting the errors from the non fraud data separately \n",
        "autoencoder.evaluate(test_NF[:,:29],test_NF[:,:29])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15942/15942 [==============================] - 0s 26us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2288174508250488, 0.2288174508250488]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "9IcoJKHKCyrG",
        "colab_type": "code",
        "outputId": "a0aa00c7-acd3-4426-8dea-24858965ba7b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Getting the errors from the fraud data separately\n",
        "autoencoder.evaluate(test_F[:,:29], test_F[:,:29])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "385/385 [==============================] - 0s 162us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18.96477629426238, 18.96477629426238]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "9sqXMtJTCyrS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Obtaining predictions for non fraud records\n",
        "predictions_nf=autoencoder.predict(test_NF[:,:29])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uG8nzuulCyrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Obtaining preictions for fraud records\n",
        "predictions_f=autoencoder.predict(test_F[:,:29])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oe26EY0aCyrY",
        "colab_type": "code",
        "outputId": "719bb35a-29e7-4b74-e424-14c705d6c6a8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Identifying the error computation method by autoencoder(Mean Squared Error). The computation is as follows \n",
        "np.mean(np.square(np.abs(test_NF[:,:29]-predictions_nf)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22881744838731152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "02_Azl7SCyrd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Computing errors on the non-fraud data\n",
        "errors_nf = np.mean(np.square(np.abs(test_NF[:,:29]-predictions_nf)), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dFHQ25P9Cyrf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Computing errors on the fraud data\n",
        "errors_f = np.mean(np.square(np.abs(test_F[:,:29]-predictions_f)), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yYqRRGjsCyri",
        "colab_type": "code",
        "outputId": "2342461c-318d-4166-e605-b034fcd1d6e7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Computing the distribution of errors in both non-fraud and fraud data\n",
        "print(np.min(errors_nf))\n",
        "print(np.max(errors_nf))\n",
        "print(np.median(errors_nf))\n",
        "\n",
        "print(np.min(errors_f))\n",
        "print(np.max(errors_f))\n",
        "print(np.median(errors_f))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.01158613765027327\n",
            "95.28864484394727\n",
            "0.12178854965091762\n",
            "0.0449454855433906\n",
            "124.47924352424931\n",
            "7.751741972679444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OnTIfBXzCyrt",
        "colab_type": "code",
        "outputId": "fa89fbf0-ca7c-4e80-9ea1-b6f97d03f112",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PLotting the error box plots \n",
        "plt.subplot(1, 2, 1)\n",
        "plt.boxplot(errors_f)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.boxplot(errors_nf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x2998e9bb390>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x2998e9bbda0>,\n",
              "  <matplotlib.lines.Line2D at 0x2998e9a2208>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x2998e9a2a58>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x2998e9a2630>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x2998e9bb4e0>,\n",
              "  <matplotlib.lines.Line2D at 0x2998e9bb978>]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x2998e969320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2SGvXoKGCyrz",
        "colab_type": "code",
        "outputId": "ce07dad1-5faa-470e-8499-1bde42defbdb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Experimentation to fix a threshold for classification of a transaction into fraud or non-fraud\n",
        "print(sum(errors_nf>np.median(errors_f)))\n",
        "print(sum(errors_f<np.median(errors_f)))\n",
        "print(sum(errors_f<np.median(errors_nf)))\n",
        "sum(errors_nf>np.median(errors_nf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "192\n",
            "6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7971"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "k50Skc3yCyr7",
        "colab_type": "code",
        "outputId": "c9f033a7-3ea9-4458-91a2-27ecd752f11e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(errors_nf.shape)\n",
        "print(errors_f.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15942,)\n",
            "(385,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-1EHP3UACysB",
        "colab_type": "code",
        "outputId": "40b5a9a6-82be-4231-8f14-a4cfe9c1a6af",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(predictions_nf.shape)\n",
        "print(predictions_f.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15942, 29)\n",
            "(385, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F82stvcdCysJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_pred = autoencoder.predict(X_test[:,:29])\n",
        "test_recon  = (((test_pred-X_test)**2).mean(-1))\n",
        "\n",
        "train_pred = autoencoder.predict(X_train_NF[:,:29])\n",
        "mean_recon = (((train_pred - X_train_NF)**2).mean(-1).mean())\n",
        "\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix\n",
        "\n",
        "scores_f1 = []\n",
        "thres = []\n",
        "\n",
        "th = 0\n",
        "for i in range(100):\n",
        "    th+=0.1\n",
        "    fraud = (test_recon>mean_recon+th)\n",
        "    scores_f1.append(f1_score(y_test,fraud))\n",
        "    thres.append(th+mean_recon)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCSt5ZXKCysN",
        "colab_type": "code",
        "outputId": "d3def512-e02e-46b2-eada-983d6a639e84",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(thres, scores_f1)\n",
        "\n",
        "print(thres[np.array(scores_f1).argmax()])\n",
        "\n",
        "fraud = (test_recon>thres[np.array(scores_f1).argmax()])\n",
        "\n",
        "confusion_matrix(y_test, fraud)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.02870254362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15883,    59],\n",
              "       [   80,   305]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x2605f412588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}